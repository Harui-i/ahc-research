# これはなに

私はAHCで強化学習(以下 RL)で1位を取ることを夢見ています。

そのためには、RLの推論をAtCoder環境(2s TLE, 1 CPU, 1024MiB RAM, 512KiB src)で高速に動かす必要があります。

なので、GPUを使った手法や、マルチコア前提の手法、そして 384KiB以上(base64で埋め込む場合)(FP16 で埋め込む場合は、2bytes/paramなので 192 Ki params以上) を埋め込むような手法は使えません。

そのような、特徴的な制約の中で、NNに不可欠な行列ベクトル積を高速に動かす方法を模索するリポジトリです。


# 目標

200 * 200 の行列ベクトル積をできるだけ高速に動かせる実装を見つけ出すことを目指します。

200 とした理由として、 AtCoderにFP16の行列をbase64で埋め込むことを考えると、埋め込めるパラメータ数Nは 512 * 1024 >= 4 * ceil(N*2/3)
となり N <= 196608となります。

4層のNNを考えると、1つの行列のサイズは sqrt(199608/4) = 221となるため、　200くらいが妥当と考えました。